{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.02: Indexing, Slicing, Splitting, and Iterating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our client wants to prove that our dataset is nicely distributed around the mean value of 100.   \n",
    "They asked us to run some tests on several subsections of it to make sure they won't get a non-descriptive section of our data.\n",
    "\n",
    "Look at the mean value of each subtask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary dependencies\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Dataset\n",
    "dataset = np.genfromtxt('../../Datasets/normal_distribution_splittable.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need several rows of our dataset to complete the given task, we have to use indexing to get the right rows.   \n",
    "To recap, index: \n",
    "- the second row \n",
    "- the last row\n",
    "- the first value of the first row\n",
    "- the last value of the second to the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the second row of the dataset (2nd row)\n",
    "second_row = dataset[1]\n",
    "\n",
    "np.mean(second_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the last element of the dataset (last row)\n",
    "last_row = dataset[-1]\n",
    "\n",
    "np.mean(last_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the first value of the first row (1st row, 1st value)\n",
    "first_val_first_row = dataset[0][0]\n",
    "\n",
    "np.mean(first_val_first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the last value of the second to last row (we want to use the combined access syntax here) \n",
    "last_val_second_last_row = dataset[-2, -1]\n",
    "\n",
    "np.mean(last_val_second_last_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the single rows and values we also need to get some subsets of the dataset.   \n",
    "Use slicing for:\n",
    "- a 2x2 slice starting from the second row and second element to the 4th element in the 4th row\n",
    "- every other element of the 5th row\n",
    "- the content of the last row in reversed order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing an intersection of 4 elements (2x2) of the first two rows and first two columns\n",
    "subsection_2x2 = dataset[1:3, 1:3]\n",
    "\n",
    "np.mean(subsection_2x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why is it not a problem if such a small subsection has a bigger standard deviation from 100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several smaller values can cluster in such a small subsection leading to the value being really low.   \n",
    "If we make our subsection larger, we have a higher chance of getting a more expressive view of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting every second element of the fifth row \n",
    "every_other_elem = dataset[4, ::2]\n",
    "\n",
    "np.mean(every_other_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversing the entry order, selecting the first two rows in reversed order\n",
    "reversed_last_row = dataset[-1, ::-1]\n",
    "\n",
    "np.mean(reversed_last_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our client's team only wants to use a small subset of the given dataset.   \n",
    "Therefore we need to first split it into 3 equal pieces and then give them the first half of the first split.   \n",
    "They sent us this drawing to show us what they need:\n",
    "```\n",
    "1, 2, 3, 4, 5, 6          1, 2     3, 4    5, 6          1, 2  \n",
    "3, 2, 1, 5, 4, 6    =>    3, 2     1, 5    4, 6    =>    3, 2    =>    1, 2\n",
    "5, 3, 1, 2, 4, 3          5, 3     1, 2    4, 3                        3, 2\n",
    "1, 2, 2, 4, 1, 5          1, 2     2, 4    1, 5          5, 3\n",
    "                                                         1, 2\n",
    "```\n",
    "\n",
    "> **Note:**   \n",
    "We are using a very small dataset here but imagine you have a huge amount of data and only want to look at a small subset of it to tweak your visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting up our dataset horizontally on indices one third and two thirds\n",
    "hor_splits = np.hsplit(dataset,(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting up our dataset vertically on index 2\n",
    "ver_splits = np.vsplit(hor_splits[0],(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requested subsection of our dataset which has only half the amount of rows and only a third of the columns\n",
    "print(\"Dataset\", dataset.shape)\n",
    "print(\"Subset\", ver_splits[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you sent over the dataset they tell you that they also need a way iterate over the whole dataset element by element as if it would be a one-dimensional list.   \n",
    "However, they want to also now the position in the dataset itself.\n",
    "\n",
    "They send you this piece of code and tell you that it's not working as mentioned.   \n",
    "Come up with the right solution for their needs using the `ndenumerate method`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over whole datagmaiset (each value in each row)\n",
    "curr_index = 0\n",
    "for x in np.nditer(dataset):\n",
    "    print(x, curr_index)\n",
    "    curr_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over whole dataset with indices matching the position in the dataset\n",
    "for index, value in np.ndenumerate(dataset):\n",
    "    print(index, value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
